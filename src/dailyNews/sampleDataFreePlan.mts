import { DailyNewsApiResponse } from "./types.mts"

export const sampleDataFreePlan: DailyNewsApiResponse = {
  "status": "success",
  "totalResults": 41,
  "results": [
    {
      "article_id": "c6423f3fa815cbdb3cf1f5d545eaa35b",
      "title": "CES gadget fest a showcase for AI-infused lifestyle",
      "link": "https://techxplore.com/news/2024-01-ces-gadget-fest-showcase-ai.html",
      "keywords": [
        "consumer & gadgets"
      ],
      "creator": null,
      "video_url": null,
      "description": "From self-driving baby carriages to ChatGPT in Volkswagen cars, artificial intelligence is expected to be center stage at the CES gadget extravaganza that formally opens Tuesday in Las Vegas.",
      "content": "From self-driving baby carriages to ChatGPT in Volkswagen cars, artificial intelligence is expected to be center stage at the CES gadget extravaganza that formally opens Tuesday in Las Vegas. The annual Consumer Electronics Show boasts more than 3,500 exhibitors and is expecting around 130,000 visitors. Companies big and small hosted previews for the press on Monday, with AI a repeated mantra as they pitched products promising better lives. LG chief executive William Cho said the world is at \"a historical turning point\" due to AI. His company aims to be part of that transformation, tapping into data gathered by sensors in hundreds of millions of smart devices in use around the world to detect patterns of behavior and provide insights, Cho said. \"We have a unique opportunity to leverage the real-life data gathered across devices in real-time. Of course, with your permission,\" he said. LG, Samsung and other TV titans also showcased AI enhancements to vastly improve images, help viewers find shows they will like, and more. Televisions will advance to a \"smart command hub\" connecting appliances, security cameras , and even incorporating thermal scanning for health insights, according to Jessica Boothe, a research director at the Consumer Technology Association that organizes CES. \"We will watch as TVs become the command center for the home beyond just streaming entertainment,\" she said. ChatGPT on wheels Volkswagen, meanwhile, presented what it described as the first vehicles built with a chatbot powered by OpenAI's ChatGPT technology. The \"Cerence Chat Pro\" digital assistant made in a partnership with Cerence Inc. will be standard in many Volkswagen vehicles starting in the second quarter of this year, according to the car maker. \"We are offering our drivers added value and direct access to the AI-based research tool,\" said Volkswagen management board member Kai Grunitz. Nvidia, whose graphics chips are coveted for their ability to handle the intense computing demands of AI, took CES as an opportunity to announce new chips for gamers and creators. Innovations being teased ahead of the CES show floor opening included tech for translating multiple languages simultaneously, and glasses for augmented reality that essentially turn the space in front of a viewer into a screen they can control with gestures. Apple, which is not at CES, said Monday that it will release its highly anticipated Vision Pro mixed reality headset in the United States on February 2, in its first major product release since the Apple Watch in 2015. Announced in June, the Vision Pro will cost a hefty $3,499 before tax, more than double the price of Meta's top-of-the-range Quest Pro headset. \"The era of spatial computing has arrived,\" said Tim Cook, Apple's CEO, calling the Vision Pro \"the most advanced consumer electronics device ever created.\" Year of AI at CES CES exhibitor and attendee numbers have jumped each year since the COVID-19 pandemic caused it to be an online-only event in 2021. While the show is increasingly a showcase for startups, big brands such as Amazon, Google, Intel, Netflix, Samsung, Sony and TikTok will also be there. \"There's some exciting innovation' there's some boring innovation, and there's some just really plain weird innovation,\" said Techsponential analyst Avi Greengart. Analysts expect it to be the year of AI when it comes to product pitches at CES. Models on which AI is built have improved dramatically since last year's CES and the debut of OpenAI's ChatGPT, and they are being applied in meaningful ways for consumers, according to Greengart. Ending Friday, CES is expected to see strong themes of AI-infused health, cars, beauty, entertainment and sustainability. \"AI will be reshaping industries beyond technology and it has the power to make life easier, more than inclusive for all,\" said Jong-Hee Han, CEO and Head of Samsung's device experience division. More than a decade of investments in AI \"are coming to life,\" he added. © 2024 AFP",
      "pubDate": "2024-01-09 09:19:35",
      "image_url": "https://scx1.b-cdn.net/csz/news/tmb/2024/the-phantom-a-wireless.jpg",
      "source_id": "phys",
      "source_priority": 6461,
      "country": [
        "united kingdom",
        "singapore",
        "australia",
        "united states of america",
        "india"
      ],
      "category": [
        "technology"
      ],
      "language": "english",
      "ai_tag": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN",
      "sentiment": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN",
      "sentiment_stats": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN"
    },
    {
      "article_id": "acb7116a93e188b85849913d52e3c9ff",
      "title": "Duolingo turns to AI to generate content, cuts 10 percent of its contractors",
      "link": "https://sea.mashable.com/tech/30361/duolingo-turns-to-ai-to-generate-content-cuts-10-percent-of-its-contractors",
      "keywords": [
        "tech",
        "apps",
        "artificial intelligence",
        "article"
      ],
      "creator": [
        "Amanda Yeo"
      ],
      "video_url": null,
      "description": "The language learning app is increasingly relying on AI to create its lessons. Duolingo has reportedly let go of approximately 10 percent of its contractors, the educational app company opting to do their work using generative AI instead. This does not bode well.A Duolingo spokesperson confirmed the job cuts to Bloomberg on Monday, though they stated …",
      "content": "Duolingo has reportedly let go of approximately 10 percent of its contractors, the educational app company opting to do their work using generative AI instead. This does not bode well. A Duolingo spokesperson confirmed the job cuts to Bloomberg on Monday, though they stated that no full-time employees were impacted. \"We just no longer need as many people to do the type of work some of these contractors were doing,\" the spokesperson said. \"Part of that could be attributed to AI.\" Duolingo further stressed to PC Mag Australia that \"these are not layoffs,\" stating that contractors had simply been \"offboarded\" after finishing their projects at the end of 2023. Reports of Duolingo's job reductions first arose late last December, when a person claiming to work at the company stated that it had cut a significant number of its contracted translators in favour of AI. \"I worked there for five years,\" they wrote on the r/Duolingo subreddit. \"Our team had four core members and two of us got the boot. The two who remained will just review AI content to make sure it’s acceptable.\" Mashable has reached out to Duolingo for comment. Regardless of the exact terminology used for the cuts, the Duolingo's latest move appears ominous to anyone who's anxious about AI taking their jobs . Duolingo has already used machine learning for years, having introduced its AI model Birdbrain in 2020 to adjust the difficulty of exercises based on users' strengths and weaknesses. However, up until 2023, \"every single exercise chosen by Birdbrain was written, reviewed, edited, and translated by human experts.\" This all changed last June, when Duolingo announced it had begun using Language Learning Model (LLM) AI in order to create entire exercises from prompts. \"With a powerful Large Language Model in the hands of Duolingo’s teaching experts, we can generate vast amounts of content for our lessons with the click of a button,\" the company said in a blog post at the time. \"Like any innovative tool, with a good operator, it can bring our in-house teachers convenience, speed, and productivity.\" Though Duolingo focused on how AI would allow it to grow smaller courses and noted that the LLM would still need human oversight, these recent job cuts indicate that it may not need quite as many humans as before. Last March the company also unveiled Duolingo Max , a premium subscription tier for their language learning app that features new tools powered by OpenAI 's GPT-4 . It currently only supports French and Spanish for English speakers on iOS , however Duolingo does plan to expand to more courses and platforms.",
      "pubDate": "2024-01-09 07:44:48",
      "image_url": "https://sm.mashable.com/mashable_sea/article/d/duolingo-t/duolingo-turns-to-ai-to-generate-content-cuts-10-percent-of_4kvt.jpg",
      "source_id": "mashable",
      "source_priority": 363,
      "country": [
        "singapore",
        "australia",
        "united states of america",
        "india",
        "united kingdom"
      ],
      "category": [
        "technology"
      ],
      "language": "english",
      "ai_tag": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN",
      "sentiment": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN",
      "sentiment_stats": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN"
    },
    {
      "article_id": "de1eae700368fb9b022311c95e989365",
      "title": "Generative AI by iStock is commercially safe image generation powered by NVIDIA Picasso",
      "link": "https://www.tweaktown.com/news/95435/generative-ai-by-istock-is-commercially-safe-image-generation-powered-nvidia-picasso/index.html",
      "keywords": null,
      "creator": [
        "Kosta Andreadis"
      ],
      "video_url": null,
      "description": "Generative AI by iStock looks impressive, with powerful editing tools and NVIDIA Picasso tech, all generated images are also commercially safe. Continue reading at TweakTown >",
      "content": "The new Generative AI by iStock image generator, powered by NVIDIA Picasso, is impressive in its capabilities and commercially safe. This is an important distinction because there's a lot of controversy surrounding what data, art, and IP generative AI models are being trained on. For example, The New York Times recently filed a lawsuit against ChatGPT and its owner, OpenAI, for using the news outlet's content to train generative AI platforms. It's asking for billions in compensation, and that's just one example. Generative AI by iStock is 'commercially safe' for use, with the generative AI trained on licensed iStock and Getty Images data - with compensation paid out to those who helped train the AI. Whatever AI images you generate 'will not be added to the creative library for others to license' too. Okay, with that out of the way, let's move on to what makes this text-to-image generation tool impressive - editing with NVIDIA Picasso. As the example above shows, you can access photos, illustrations, and even videos to generate new visuals up to 4K. What gives Generative AI by iStock its edge is the powerful editing you can do, like selecting regions to add details or even taking an existing image and expanding it to fill a new aspect ratio or perspective. In the video above, we see this in action - adding a person into the image at a specific spot and zooming out to showcase more of the landscape. Another powerful editing feature coming soon will be the ability to intuitively replace elements or objects in an image. Generative AI by iStock, powered by NVIDIA Picasso, is available now. For $22.99 USD, you get 100 generations (each including four distinct images) safe for commercial use.",
      "pubDate": "2024-01-09 03:02:03",
      "image_url": "https://www.tweaktown.com/images/news/9/5/95435_01_generative-ai-by-istock-is-commercially-safe-image-generation-built-on-nvidia-picasso.jpg",
      "source_id": "tweaktown",
      "source_priority": 43825,
      "country": [
        "united states of america"
      ],
      "category": [
        "technology"
      ],
      "language": "english",
      "ai_tag": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN",
      "sentiment": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN",
      "sentiment_stats": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN"
    },
    {
      "article_id": "8722222b5603d37290acc6f2975d97bc",
      "title": "Siemens teams up with Microsoft on cross-industry AI adoption",
      "link": "https://venturebeat.com/ai/siemens-teams-up-with-microsoft-on-cross-industry-ai-adoption/",
      "keywords": [
        "ai",
        "business",
        "gamesbeat",
        "category-/business & industrial",
        "category-/computers & electronics",
        "ces 2024",
        "microsoft",
        "roland busch",
        "satya nadella",
        "siemens"
      ],
      "creator": [
        "Dean Takahashi",
        "Siemens teams up with Microsoft on cross-industry AI adoption"
      ],
      "video_url": null,
      "description": "Siemens and Microsoft have teamed up to drive cross-industry adoption for artificial intelligence.",
      "content": "Do you want to get the latest gaming industry news straight to your inbox? Sign up for our daily and weekly newsletters here . Siemens and Microsoft have teamed up to drive cross-industry adoption for artificial intelligence. The companies made the announcement at CES 2024 during the opening keynote speech of Roland Busch, CEO of Siemens , as they announced the Siemens Industrial Copilot. That’s a generative AI-powered assistant aiming to amplify human-machine collaboration and productivity across various sectors. The deal between these industry giants is in recognition of the shift in AI technology, starting with Siemens Industrial Copilot, designed specifically for the manufacturing sector. The copilot is a collaborative creation utilizing Microsoft’s Azure OpenAI Service and Siemens’ Xcelerator digital business platform, promising to revolutionize industrial processes. Busch also showed how Sony and Siemens are engaged in immersive engineering using XR headsets to help visualize engineering designs. The AI Impact Tour Getting to an AI Governance Blueprint – Request an invite for the Jan 10 event. “Technology is hidden but it’s everywhere,” Busch said. “The technology has a name. The industrial metaverse. The industrial metaverse will redefine reality and transform every day for everyone.” Satya Nadella, CEO of Microsoft, said in a statement, “With this next generation of AI, we have a unique opportunity to accelerate innovation across the entire industrial sector. We’re building on our longstanding collaboration with Siemens and bringing together AI advances across the Microsoft Cloud with Siemens’ industrial domain expertise to empower both frontline and knowledge workers with new, AI-powered tools, starting with Siemens Industrial Copilot.” Busch said in a statement, “Together with Microsoft, our shared vision is to empower customers with the adoption of generative AI. This has the potential to revolutionize the way companies design, develop, manufacture, and operate. Making human-machine collaboration more widely available allows engineers to accelerate code development, increase innovation and tackle skilled labor shortages.” Busch said it can take airplane manufacturers 10 years to make a new generation of an airplane. They can use simulations to speed it up, but it still takes time to get it done. With the advances of AI, the ability to simulate and be more efficient is only getting better. Siemens Industrial Copilot’s capabilities are poised to streamline complex automation code generation, optimization, and debugging processes, reducing what once took weeks to mere minutes, the company said. This advancement draws from Siemens’ digital platform and Microsoft’s AI service, ensuring customer data control without utilization for underlying AI model training. The copilot’s promise extends beyond code generation, offering detailed maintenance instructions for staff and instant access to simulation tools for engineers through natural language interaction, fostering a new level of productivity and efficiency in industrial operations. The collaboration is not confined to manufacturing; both companies envision AI copilots aiding professionals in various sectors, including infrastructure, transportation, and healthcare. Early adopters like Schaeffler AG, an automotive supplier, have embraced generative AI, utilizing it to enhance engineering phases and reduce downtimes in operations. AWS also is partnering with Siemens on this journey. Siemens believes the metaverse isn’t just a place you go to escape the real world. It believes the industrial metaverse is the place you go to make the real world better. It is joining the alliance for OpenUSD, which is being touted by Nvidia and its allies. OpenUSD was originally created and then open sourced by Pixar. Sony also showed off its brand new head-mounted display for content creation. Klaus Rosenfeld, CEO of Schaeffler Group, said in a statement, “Siemens Industrial Copilot will enhance our team’s efficiency, reduce repetitive tasks, and unlock creativity—an exciting collaboration with Siemens and Microsoft.” The Siemens Teamcenter app for Microsoft Teams will enhance virtual collaboration by connecting product design and manufacturing lifecycle functions, bridging the gap between frontline workers and engineering teams. This integration aims to make data more accessible for factory and field service workers, facilitating their contribution to design and manufacturing processes seamlessly. Siemens will unveil more about Siemens Industrial Copilot at the SPS expo in Nuremberg, Germany, in November 2023. GamesBeat's creed when covering the game industry is \"where passion meets business.\" What does this mean? We want to tell you how the news matters to you -- not just as a decision-maker at a game studio, but also as a fan of games. Whether you read our articles, listen to our podcasts, or watch our videos, GamesBeat will help you learn about the industry and enjoy engaging with it. Discover our Briefings.",
      "pubDate": "2024-01-09 02:30:00",
      "image_url": "https://venturebeat.com/wp-content/uploads/2024/01/microsoft.jpg?fit=750%2C488&strip=all",
      "source_id": "venturebeat",
      "source_priority": 11316,
      "country": [
        "united states of america"
      ],
      "category": [
        "science",
        "technology"
      ],
      "language": "english",
      "ai_tag": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN",
      "sentiment": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN",
      "sentiment_stats": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN"
    },
    {
      "article_id": "e4d4b864d5dc791a1d432a495e284d0f",
      "title": "‘Not Telling The Full Story’: OpenAI Challenges NYT’s Copyright Lawsuit Claims – Decrypt",
      "link": "https://zephyrnet.com/not-telling-the-full-story-openai-challenges-nyts-copyright-lawsuit-claims-decrypt/",
      "keywords": [
        "ai",
        "blockchain",
        "60",
        "a",
        "accurate",
        "accused",
        "acknowledged",
        "acted",
        "addressing",
        "admits",
        "ai model",
        "ai models",
        "ai tools",
        "ai training",
        "all",
        "allegations",
        "alleged",
        "also",
        "amendment",
        "an",
        "analyze",
        "and",
        "and the",
        "another",
        "any",
        "are",
        "argue",
        "argued",
        "art",
        "articles",
        "artist",
        "as",
        "assist",
        "attempts",
        "audiences",
        "authors",
        "available",
        "axel springer",
        "bad",
        "battle",
        "be",
        "because",
        "behave",
        "being",
        "believe",
        "best",
        "best-selling",
        "between",
        "books",
        "both",
        "branch",
        "brought",
        "businesses",
        "but",
        "by",
        "came",
        "can",
        "case",
        "challenges",
        "championing",
        "characteristics",
        "cherry",
        "claims",
        "collaboration",
        "commitment",
        "common",
        "companies",
        "company",
        "compensation",
        "compete",
        "comprising",
        "conditions",
        "considerations",
        "constructive",
        "content",
        "content creation",
        "content creators",
        "continually",
        "conversation",
        "copyright",
        "copyrighted",
        "cost",
        "could",
        "courts",
        "crafted",
        "create",
        "creation",
        "creators",
        "criticizing",
        "crucial",
        "crypto",
        "crypto news",
        "daily",
        "data",
        "datasets",
        "decide",
        "declared",
        "decrypt",
        "defense",
        "depending",
        "deployment",
        "design",
        "design process",
        "despite",
        "developed",
        "developer",
        "digital",
        "digital era",
        "divert",
        "doesn",
        "doesn’t",
        "doing",
        "don",
        "don't",
        "edited",
        "editors",
        "either",
        "elaborated",
        "emphasized",
        "emphasizing",
        "era",
        "ethical",
        "even",
        "evidence",
        "examples",
        "existing",
        "explain",
        "explicit",
        "exploited",
        "extend",
        "failure",
        "fair",
        "fairly",
        "faith",
        "filed",
        "find",
        "first",
        "first amendment",
        "for",
        "formed",
        "freedoms",
        "from",
        "full",
        "fundamental",
        "future",
        "future of ai",
        "game",
        "generate",
        "generated",
        "get",
        "goal",
        "growth",
        "had",
        "hard",
        "highlighting",
        "hinted",
        "history",
        "hopeful",
        "how",
        "however",
        "if",
        "illustrations",
        "impact",
        "implying",
        "in",
        "inbox",
        "includes",
        "including",
        "incomplete",
        "independent",
        "industry",
        "influence",
        "instead",
        "instructed",
        "integration",
        "intellectual",
        "intellectual property",
        "intentionally",
        "internet",
        "into",
        "is",
        "issue",
        "it",
        "its",
        "journalism",
        "key",
        "key points",
        "kind",
        "language",
        "laws",
        "lawsuit",
        "leading",
        "learn",
        "learning",
        "legal",
        "lengthy",
        "like",
        "long",
        "long history",
        "making",
        "making progress",
        "manipulated",
        "manipulation",
        "manner",
        "many",
        "materials",
        "matter",
        "memorization",
        "merit",
        "methods",
        "mitigate",
        "model",
        "models",
        "more",
        "more accurate",
        "most",
        "movement",
        "movies",
        "mutual",
        "nature",
        "negative",
        "network",
        "neural",
        "neural network",
        "new",
        "new york",
        "new york times",
        "news",
        "newspaper",
        "no",
        "normal",
        "now",
        "obtained",
        "of",
        "often",
        "older",
        "olive",
        "on",
        "openai",
        "opt",
        "or",
        "order",
        "organizations",
        "original",
        "other",
        "our",
        "out",
        "outcome",
        "outlet",
        "over",
        "owners",
        "paintings",
        "part",
        "partner",
        "partnership",
        "party",
        "patterns",
        "people",
        "permission",
        "picked",
        "plato",
        "plato data intelligence",
        "platodata",
        "points",
        "positive",
        "potential",
        "potentially",
        "practice",
        "process",
        "process for",
        "production",
        "products",
        "programmed",
        "progress",
        "prompt",
        "prompts",
        "property",
        "provide",
        "providing",
        "publicly",
        "publisher",
        "publishers",
        "rare",
        "ready",
        "receipts",
        "recently",
        "regurgitate",
        "reporting",
        "respect",
        "response",
        "retain",
        "rights",
        "rolling",
        "rolling stone",
        "root",
        "ryan",
        "s",
        "said",
        "saying",
        "scenario",
        "seems",
        "selling",
        "shape",
        "similar",
        "so",
        "society",
        "somewhere",
        "songs",
        "sources",
        "specific",
        "stay",
        "still",
        "stone",
        "story",
        "structures",
        "student",
        "studies",
        "style",
        "such",
        "sued",
        "suggests",
        "sum",
        "summaries",
        "support",
        "surrounding",
        "t",
        "technology",
        "telling",
        "texts",
        "that",
        "that are",
        "the",
        "the future",
        "the most",
        "the new york times",
        "the way",
        "their",
        "these",
        "they",
        "things",
        "third",
        "third-party",
        "this",
        "time",
        "times",
        "to",
        "tools",
        "top",
        "train",
        "trained",
        "trainers",
        "training",
        "training methods",
        "trick",
        "trigger",
        "typically",
        "uncommon",
        "under",
        "understand",
        "understanding",
        "undoubtedly",
        "unfairly",
        "unfolds",
        "up",
        "updates",
        "use",
        "used",
        "using",
        "validity",
        "value",
        "various",
        "vast",
        "very",
        "voices",
        "was",
        "way",
        "we",
        "websites",
        "what",
        "when",
        "whether",
        "which?",
        "why",
        "widely",
        "will",
        "with",
        "with the",
        "without",
        "work",
        "working",
        "would",
        "wrote",
        "years",
        "years ago",
        "york",
        "your",
        "zephyrnet",
        "zero"
      ],
      "creator": [
        "Republished By Plato"
      ],
      "video_url": null,
      "description": "In response to a lawsuit filed by the New York Times, in which the news outlet accused OpenAI of using its news content to train its AI model, OpenAI has brought receipts. The leading AI developer leaned into its oft-declared commitment to the news industry, declaring, “We support journalism, partner with news organizations, and believe […]",
      "content": "In response to a lawsuit filed by t he New York Times , in which the news outlet accused OpenAI of using its news content to train its AI model, OpenAI has brought receipts. The leading AI developer leaned into its oft-declared commitment to the news industry, declaring, “We support journalism, partner with news organizations, and believe The New York Times lawsuit is without merit.” OpenAI also accused the New York Times of incomplete reporting, alleging that “the New York Times is not telling the full story.” The company suggests that the examples used by the newspaper came from older articles that are widely available on third-party websites, and also hinted that the New York Time had crafted its AI prompts to generate the most damning evidence. “It seems they intentionally manipulated prompts, often including lengthy excerpts of articles, in order to get our model to regurgitate,” OpenAI said, implying that the New York Times acted in bad faith by providing unnatural prompts as evidence. “Even when using such prompts, our models don’t typically behave the way the New York Times insinuates, which suggests they either instructed the model to regurgitate or cherry-picked their examples from many attempts.” Prompt manipulation is a common practice in which people can trick an AI model into doing things it’s not programmed to do, using specific prompts that trigger a very specific response that would not be obtained under normal conditions. OpenAI emphasized its collaboration with the news industry. “We work hard in our technology design process to support news organizations,” the company wrote, highlighting the deployment of AI tools that assist reporters and editors and the goal of mutual growth for both AI and journalism. OpenAI recently formed a partnership with Axel Springer —publisher of Rolling Stone— to provide more accurate news summaries. Addressing the issue of content “regurgitation,” as the New York Times alleged, OpenAI admits that it is an uncommon but existing issue that they are working to mitigate. “Memorization is a rare failure of the learning process that we are continually making progress on,” they explain, and defended their training methods. “Training AI models using publicly available internet materials is fair use.” Even so, OpenAI acknowledged the validity of ethical considerations by providing an opt-out process for publishers. AI training and content storage The battle between content creators and AI companies seems to be a zero sum game for now, as the root of it all is the fundamental way that AI models are trained. These models are developed using vast datasets comprising texts from various sources, including books, websites, and articles. Other models use paintings, illustrations, movies, voices, and songs, depending on what they are trained to create. These models do not retain specific articles or data, however. Instead, they analyze these materials to learn language patterns and structures. This process is crucial to understanding the nature of the allegations and OpenAI’s defense, and why AI trainers believe their businesses are using content in a fair manner—similar to how an art student studies another artist or art style to understand its characteristics. However, creators—including the New York Times and best-selling authors—argue that companies like OpenAI are using their content in bad faith. They assert that their intellectual property is being exploited without permission or compensation, leading to AI-generated products that could potentially compete with and divert audiences from their original content. The New York Times sued OpenAI saying that the use of their content without explicit permission undercuts the value of original journalism, emphasizing the potential negative impact on the production of independent journalism and its cost to society. And, it could be argued, no matter how elaborated the prompt is, if it “regurgitated” any kind of copyrighted content, it’s because it was used. Whether it was used fairly or unfairly is up to the courts to decide. This legal battle is part of a legal movement that could shape the future of AI, copyright laws, and journalism. As the case unfolds, it will undoubtedly influence the conversation surrounding the integration of AI in content creation and the rights of intellectual property owners in the digital era. Still, OpenAI doesn’t believe this is a zero-sum scenario. Despite criticizing the lawsuit’s key points, Altman’s company said it is ready to extend an olive branch and find a positive outcome somewhere. “We are hopeful for a constructive partnership with the New York Times and respect its long history, which includes reporting the first working neural network over 60 years ago and championing First Amendment freedoms.” Edited by Ryan Ozawa . Stay on top of crypto news, get daily updates in your inbox. SEO Powered Content & PR Distribution. Get Amplified Today. PlatoData.Network Vertical Generative Ai. Empower Yourself. Access Here. PlatoAiStream. Web3 Intelligence. Knowledge Amplified. Access Here. PlatoESG. Carbon, CleanTech, Energy, Environment, Solar, Waste Management. Access Here. PlatoHealth. Biotech and Clinical Trials Intelligence. Access Here. Source: https://decrypt.co/212077/not-telling-the-full-story-openai-challenges-nyts-copyright-lawsuit-claims",
      "pubDate": "2024-01-09 00:47:08",
      "image_url": "https://zephyrnet.com/wp-content/uploads/2024/01/not-telling-the-full-story-openai-challenges-nyts-copyright-lawsuit-claims-decrypt.jpg",
      "source_id": "zephyrnet",
      "source_priority": 3670004,
      "country": [
        "united states of america"
      ],
      "category": [
        "technology"
      ],
      "language": "english",
      "ai_tag": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN",
      "sentiment": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN",
      "sentiment_stats": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN"
    },
    {
      "article_id": "de34b93ee4bd4fffb38af74c8520a7a9",
      "title": "Cerebras Systems Wins A Major New Client: The Mayo Clinic",
      "link": "https://www.forbes.com/sites/karlfreund/2024/01/08/cerebras-systems-wins-a-major-new-client-the-mayo-clinic/",
      "keywords": [
        "enterprise tech",
        "/enterprise-tech",
        "innovation",
        "/innovation",
        "enterprise tech",
        "/enterprise-tech",
        "standard"
      ],
      "creator": [
        "Karl Freund, Contributor",
        "",
        "Karl Freund, Contributor",
        "",
        ""
      ],
      "video_url": null,
      "description": "The Mayo Clinic has built one of the world’s largest and most valuable health data sets in the world.",
      "content": "The Mayo Clinic has one of the world’s most extensive and valuable health data sets. AI can now transform that treasure trove into better health outcomes and scientific understanding, and Cerebras has been selected to help. As we noted last Fall , Cerebras is one of the few AI hardware startups to land large customers and is on target for something close to a billion dollars in revenue. While the company’s Wafer Scale Engine made it famous, its passion and capacity for solving complex problems is becoming an equally important differentiator. Cerebras’ AI expertise was critical to the Mayo Clinic as it decided to select Cerebras as its lead partner in developing large language models (LLMs) for medical applications. What Did Cerebras Announce? Scraping the internet for training models such as OpenAI GPT-4 can create impressive AIs. Still, such models lack the specific scientific data that resides inside institutional vaults such as those found in the Mayo Clinic. Consequently, Mayo and others must train new models using internal, confidential, multi-modal data from patient diagnostics, treatments, outcomes, imaging, and molecular research. Cerebras brings AI and Hardware to the table, and Mayo Clinic brings data and domain expertise. ... [+] Combined, they will build state of the art medical AI models. The first deliverable of the partnership is a Rheumatoid Arthritis diagnostic model, which will combine data from patient records, DNA and drug molecules to help match RA patients with the best therapeutics to manage their disease. Mayo and Cerebras plan to develop a similar model for pancreatic cancer, the fourth leading cause of cancer death in both men and women, taking nearly a half million lives globally in 2020. “Mayo Clinic selected Cerebras as its first generative AI collaborator for its large-scale, domain-specific AI expertise to accelerate breakthrough insights for the benefit of patients,” said Matthew Callstrom, MD, PhD, of the Mayo Clinic. Details of the agreement were not disclosed regarding the number of CS-2s and whether this is cloud, on-prem, or both (probably the latter). However, Cerebras CEO Andrew Feldman described the arrangement as multi-year and “many, many millions of dollars.” Conclusions Cerebras has another notch in its ever-growing success belt. It has now positioned itself in a leadership role in accelerating AI in health care and pharmaceuticals, adding to its existing projects with Glaxo Smith Klein and M42. This design win reinforces our viewpoint that Cerebras will emerge as one of the few highly successful data center AI hardware startups. They have the gear, the software, and the expertise needed to attract enterprises looking for the best help they can find to build their specific AI solutions. Disclosures : This article expresses the opinions of the author and is not to be taken as advice to purchase from or invest in the companies mentioned. My firm, Cambrian-AI Research, is fortunate to have many semiconductor firms as our clients, including BrainChip, Cadence, Cerebras Systems, Esperanto, IBM, Intel, NVIDIA, Qualcomm, Graphcore, SImA,ai, Synopsys, Tenstorrent, Ventana Microsystems, and scores of investors. We have no investment positions in any of the companies mentioned in this article. For more information, please visit our website at https://cambrian-AI.com .",
      "pubDate": "2024-01-09 00:15:00",
      "image_url": "https://imageio.forbes.com/specials-images/imageserve/65986cb07998c4967d8d0582/0x0.jpg?width=960",
      "source_id": "forbes",
      "source_priority": 57,
      "country": [
        "united states of america"
      ],
      "category": [
        "technology"
      ],
      "language": "english",
      "ai_tag": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN",
      "sentiment": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN",
      "sentiment_stats": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN"
    },
    {
      "article_id": "ea5cb47214de347c2a2a4a5ac4090630",
      "title": "Asus ROG Phone 8 Pro hands-on: The gaming phone grows up",
      "link": "https://www.tomsguide.com/reviews/asus-rog-phone-8-pro-hands-on-the-gaming-phone-grows-up",
      "keywords": [
        "smartphones"
      ],
      "creator": [
        "richard.priday@futurenet.com (Richard Priday)"
      ],
      "video_url": null,
      "description": "With a new telephoto camera, a fresh, classy design and even more powerful internals, Asus hopes the ROG Phone 8 will offer users an awesome mobile gaming experience without compromising on essential flagship phone features.",
      "content": "It pains me to say it but there's more to life than gaming. And strangely this is a lesson Asus seems to have taken to heart with the newly announced ROG Phone 8 and ROG Phone 8 Pro — a pair of gaming phones that are trying not to shout about it. You still get a big handset with a barrelful of RAM and the latest chipset, plus capacitive triggers and an optional cooler to stick to the back of the phone for your intensive gaming needs. But now there's a camera system with the specs to take on typical flagship phones, and a design that's focused more on practicality than RGB-lit drama. We can't show you everything about the Asus ROG Phone 8 series just yet. But we can take you through all the important parts of this phone in this initial hands-on, and show you how Asus plans to tempt regular phone buyers to defect to the Republic of Gamers. Asus has the ROG Phone 8 and ROG Phone 8 Pro up for pre-order from January 9, with full sales opening on February 4. The standard ROG Phone 8 comes in a 12GB RAM/256GB storage variant only, and costs £949. The ROG Phone 8 Pro, which differs slightly in design and has 16GB RAM and 512GB storage, will instead cost £1,099. There's also the ROG Phone Pro 8 Edition, which takes the memory up to 24GB RAM and 1TB storage — while lumping in a free AeroActive Cooler X accessory in the box for £1,299. With these prices in mind, Asus is going up against phones like the Galaxy S23 Plus and Galaxy S23 Ultra (and soon the Galaxy S24 Plus and Galaxy S24 Ultra ), the incoming OnePlus 12 , the iPhone 15 Pro Max and perhaps also the Pixel 8 Pro depending on where you draw your price brackets. Hopefully with Asus' change of direction with this year's iteration, the ROG Phone 8 will sit more comfortably in comparison with these types of phones rather than other new gaming-focused ones like the much cheaper RedMagic 9 Pro . Whether you go pro or not, the ROG Phone 8 is lighter, shorter and wider compared to last year’s ROG Phone 7 . But you still get a 6.78-inch FHD OLED display with a 1 - 120Hz adaptive refresh rate, and a 165Hz peak for certain games. Peak brightness is rated at 2,500 nits, which is enough to challenge top phones like the Galaxy S23 Ultra and iPhone 15 Pro if accurate. You can also enjoy more of the display now that the traditional top bezel of ROG Phones has been replaced with a punch-hole camera like other recent Android phones. It helps the ROG Phone 8 look as up-to-date as its other specs would suggest, even if hardcore gamers may want to fiddle with the display settings to stop the cutout from blocking parts of an in-game interface. The sharp-edged camera block and glossy accents to the ROG Phone 8 Pro’s matte-textured back do hint at this phone's gaming pedigree, but it's not as shouty as other gaming phones. That is until the AniMe Vision lighting activates. This consists of a matrix of white LEDs that are invisible when switched off, but can light up and animate in a number of pre-loaded patterns (or in a way you design yourself) when you open a game, get a notification or for many other common scenarios. The standard ROG Phone 8 instead uses a four-zone RGB logo which offers more color but doesn't pull the same disappearing act when you switch it off. Another major design change is the removal of the rear cooling cutout Asus used to include on its gaming phones. That means that the ROG Phone has finally achieved IP68 dust/water resistance, something that marks it out against other gaming phones. Asus is also using Gorilla Glass Victus 2 to protect the screen further. We're still not done with the ROG Phone 8’s physical peculiarities though. It offers dual USB-C ports: one on the left side of the bottom edge (conveniently leaving room for a headphone jack) and the other on the left edge for powering up when you're holding the phone horizontally. Your color choices for the ROG Phone 8 are a little limited. The base model is the only one that actually gets a choice, of either Rebel Grey or a glossy Phantom Black. The Pro gets a matte-textured Phantom Black only. For a gaming phone, the Asus ROG Phone 8 is oddly camera-focused, and perhaps all the better for it. Its main camera is 50MP like the last ROG Phone, but it’s now gimbal-stabilized like the Asus Zenfone 10 for smoother photo snapping and video recording. Not many phones offer this which could give the ROG Phone an unusually large advantage for action or tracking shots. Asus fitted this main camera with a 2x lossless mode as well, common to recent flagship phones like the Samsung Galaxy S23 series and the iPhone 15 Pro. Meanwhile, the ultrawide camera has a 13MP sensor, also back from the ROG Phone 7, but with a new lens to reduce distortion. The big upgrade this year is a 32MP 3x telephoto camera, replacing the macro sensor Asus had used on ROG Phones previously. This is a major boost that means one of the biggest feature sacrifices you had to make previously to go for a gaming phone is no longer a factor. It’s quite the shake-up. The only potential issue is that this camera takes 8MP photos instead of full 32MP ones, presumably to improve image brightness and color via pixel-binning. That's on the low-res side compared to the 10MP zoom shots you get from a Galaxy S23, or the 12MP ones from an iPhone 15 Pro. The last camera to mention is the 32MP selfie camera too. This also shoots 8MP photos, but considering we were pleasantly surprised at the quality of the ROG Phone 7’s selfies last year, we’ll stay optimistic that it works well. Both ROG Phone 8 variants feature a Snapdragon 8 Gen 3 chipset, making them part of an exclusive club of early users of the chip. We're expecting great things in our benchmark testing as a result, even if more Android devices are expected to adopt the chip in future and likely offer similar or perhaps better figures. One thing that could give the ROG Phone 8 a long-term edge is its X Mode performance profile. This bumps up the speed of the Snapdragon chip but at the expense of the phone running hotter and more power-hungrily. Although by how much remains to be seen. Where the Pro and non-Pro ROGs differ is memory. The base model has a single 12GB RAM and 256GB of storage variant, which is already a lot of gigs to have. The Pro gets 16GB or 24GB RAM and 512GB or 1TB storage depending if you buy the regular Pro or the Pro Edition. A 5,500 mAh battery in the Asus ROG Phone 8 and 8 Pro means we've got a smaller capacity than last year's 6,000 mAh ROG Phone 7. Hopefully this doesn't impact battery life too much, as the ROG Phone 7 Ultimate was our phone battery life champion for 2023 , but if the phone lasts significantly less time on our battery test, we’ll know what to blame. Fortunately, Asus’ 65W charging system is unchanged, which Asus promises will fill the phone from empty in 39 minutes. You also get 15W wireless charging for when you need a slower but cable-less top-up. A new ROG Phone means a new clip-on cooler, and this time we have the AeroActive Cooler X, which comes by default with the most expensive Pro Edition version of the ROG Phone 8 but can also be bought for $100 separately. When attached to the ROG Phone 8’s side USB-C port, the AeroActive Cooler enhances the improved internal passive cooling system even further, and can optionally unlock an even more powerful version of X Mode for maximum performance potential. It also comes with passthrough USB-C charging, a second headphone jack, a kickstand and two additional triggers on the back for you to use when gaming. Add in the two capacitive \"AirTrigger\" buttons included on the phone's left edge, and that's a lot of control customization. On the software side, Asus is promoting the new ROG Phone’s Background mode for games. That way you can keep the grind going while using your phone for something else. On top of that, there's AI-assisted automatic game clip recording for capturing all your best moments during play, and an AI grabber tool that lets you make quick web searches of on-screen text in your game. Sounds very useful if you need a walkthrough for how to deal with something new or unexpected. All of this runs alongside Android 14 , although Asus has once again done a good job of making the basic interface look less generic. What we’re less keen on is the software update schedule, which covers only two years of full updates and four years of security updates. That's severely lacking compared to the competition, all of which are now offering four years or more of full updates. As things stand, the Asus ROG Phone 8's pitch is very appealing. It'll in theory still offer all the mobile gaming comforts we're used to from previous ROG Phones, but with fewer sacrifices to the all-round performance that normal Android flagship phones provide so well. Asus has certainly provided the specs required to meet this claim, although it's a shame the battery's had to shrink as a result. Plus the 32MP sensors taking 8MP shots thing is a little odd, at least on paper. But the ROG Phone 8 still has the key gaming credentials of a big bright display, the latest chipset and lots of RAM, so even if Asus’ gambit to pull in more typical smartphone buyers doesn’t work, gaming phone fans will hopefully still find a lot to like here.",
      "pubDate": "2024-01-09 00:00:00",
      "image_url": "https://cdn.mos.cms.futurecdn.net/6QH5cWdLYZXxwmaFJQahgC.jpg",
      "source_id": "tomsguide",
      "source_priority": 203,
      "country": [
        "united states of america"
      ],
      "category": [
        "technology"
      ],
      "language": "english",
      "ai_tag": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN",
      "sentiment": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN",
      "sentiment_stats": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN"
    },
    {
      "article_id": "b47150325d1ace225cffe770748559eb",
      "title": "OpenAI says it's 'impossible' to create ChatGPT without copyrighted content, as if that's somehow a good excuse",
      "link": "https://www.pcgamer.com/openai-says-its-impossible-to-create-chatgpt-without-copyrighted-content-as-if-thats-somehow-a-good-excuse",
      "keywords": [
        "openai",
        "microsoft",
        "chatgpt",
        "copyright",
        "ai"
      ],
      "creator": [
        "andy.chalk@pcgamer.com (Andy Chalk)"
      ],
      "video_url": null,
      "description": "In the face of a growing number of lawsuits, OpenAI insists that the use of copyrighted content to train LLMs is fair use.",
      "content": "Just a couple weeks after being sued by the New York Times over allegations that it copied and used \"millions\" of copyrighted news articles to train its large-language models, OpenAI has told the UK's House of Lords communications and digital select committee (via The Guardian ) that it has to use copyrighted materials to build its systems because otherwise, they just won't work . Large-language models—LLMs—that form the basis of AI systems like OpenAI's ChatGPT chatbot harvest massive amounts of data from online sources in order to \"learn\" how to function. That becomes a problem when questions of copyright come into play. The Times' lawsuit, for instance, says Microsoft and OpenAI \"seek to free-ride on The Times' massive investment in its journalism by using it to build substitutive products without permission or payment.\" It's not the only one taking issue with that approach: A group of 17 authors including John Grisham and George RR Martin filed suit against OpenAI in 2023, accusing it of \" systematic theft on a mass scale .\" In its presentation to the House of Lords, OpenAI doesn't deny the use of copyrighted materials, but instead says it's all fair use—and anyway, it simply has no choice. \"Because copyright today covers virtually every sort of human expression—including blog posts, photographs, forum posts, scraps of software code, and government documents—it would be impossible to train today's leading AI models without using copyrighted materials,\" it wrote. \"Limiting training data to public domain books and drawings created more than a century ago might yield an interesting experiment, but would not provide AI systems that meet the needs of today's citizens.\" I don't find it a particularly compelling argument. If I, for instance, got busted knocking over a bank, I don't think it would carry much weight with the cops if I told them that it was the only way to provide myself with the money that meets the needs of me. That is admittedly a bit simplistic, and it's possible that OpenAI's lawyers will be able to successfully argue that using copyrighted materials without permission to train its LLMs falls within the confines of fair use. But to my ear the justification for using copyrighted works without a green-light from the original creator ultimately boils down to, \"But we really, really wanted to.\" Fair use is central to OpenAI's position that the use of copyrighted materials doesn't actually break any rules. It said in its filing with the House of Lords that \"OpenAI complies with the requirements of all applicable laws, including copyright laws,\" and went deeper on that point in an update released today . \"Training AI models using publicly available internet materials is fair use, as supported by long-standing and widely accepted precedents,\" OpenAI wrote. \"We view this principle as fair to creators, necessary for innovators, and critical for US competitiveness. \"The principle that training AI models is permitted as a fair use is supported by a wide range of academics, library associations, civil society groups, startups, leading US companies, creators, authors, and others that recently submitted comments to the US Copyright Office. Other regions and countries, including the European Union, Japan, Singapore, and Israel also have laws that permit training models on copyrighted content—an advantage for AI innovation, advancement, and investment.\" We build AI to empower people, including journalists.Our position on the @nytimes lawsuit:• Training is fair use, but we provide an opt-out• \"Regurgitation\" is a rare bug we're driving to zero• The New York Times is not telling the full storyhttps://t.co/S6fSaDsfKb January 8, 2024 OpenAI also drew a hard line against the New York Times' lawsuit in the update, essentially accusing the Times of ambushing it in the midst of partnership negotiations. Perhaps taking a lesson from Twitter , which accused Media Matters of manipulating \"inorganic combinations of advertisements and content\" in order to make pro-Nazi ads appear next to posts by major advertisers, OpenAI also said the Times \"manipulated prompts, often including lengthy excerpts of articles, in order to get our model to regurgitate\" its content and style, a central element of complaints against AI . \"Even when using such prompts, our models don’t typically behave the way The New York Times insinuates, which suggests they either instructed the model to regurgitate or cherry-picked their examples from many attempts,\" OpenAI wrote. OpenAI said in its House of Lords filing that it is \"continuing to develop additional mechanisms to empower rightsholders to opt out of training,\" and is pursuing deals with various agencies like the one it signed with Associated Press in 2023 that it hopes will \"yield additional partnerships soon.\" But to me that lands like a \"forgiveness instead of permission\" approach: OpenAI is already scraping this stuff anyway, so agencies and outlets might as well sign some kind of deal before a court rules that AI companies can do whatever they want.",
      "pubDate": "2024-01-08 22:38:37",
      "image_url": "https://cdn.mos.cms.futurecdn.net/3R2ecLjwZNwFEP7tKKPhpC.jpg",
      "source_id": "pcgamer",
      "source_priority": 571,
      "country": [
        "united states of america",
        "australia",
        "canada",
        "united kingdom"
      ],
      "category": [
        "technology"
      ],
      "language": "english",
      "ai_tag": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN",
      "sentiment": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN",
      "sentiment_stats": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN"
    },
    {
      "article_id": "2715d6d7478237d8a5d0eabf8f72d64b",
      "title": "OpenAI argues it is ‘impossible’ to train ChatGPT without copyrighted work",
      "link": "https://www.popsci.com/technology/openai-copyright-fair-use/",
      "keywords": [
        "ai",
        "technology",
        "art",
        "artificial intelligence",
        "news",
        "policy",
        "privacy"
      ],
      "creator": [
        "Andrew Paul"
      ],
      "video_url": null,
      "description": "OpenAI said The New York Times' recent lawsuit against the tech company is 'without merit.'. Deposit PhotosThe tech company says it has 'a mission to ensure that artificial general intelligence benefits all of humanity.' The post OpenAI argues it is ‘impossible’ to train ChatGPT without copyrighted work appeared first on Popular Science.",
      "content": "2023 marked the rise of generative AI and 2024 could well be the year its makers reckon with the technology’s fallout of the industry-wide arms race. Currently, OpenAI is aggressively pushing back against recent lawsuits’ claims that its products including ChatGPT are illegally trained on copyrighted texts. What’s more, the company is making some bold legal claims as to why their programs should have access to other people’s work. [Related: Generative AI could face its biggest legal tests in 2024 .] In a blog post published on January 8, OpenAI accused The New York Times of “not telling the full story” in the media company’s major copyright lawsuit filed late last month. Instead, OpenAI argues its scraping of online works falls within the purview of “fair use.” The company additionally claims that it currently collaborates with various news organizations (excluding, among others, The Times ) on dataset partnerships, and dismisses any “regurgitation” of outside copyrighted material as a “rare bug” they are working to eliminate. This is attributed to “memorization” issues that can be more common when content appears multiple times within training data, such as if it can be found on “lots of different public websites.” “The principle that training AI models is permitted as a fair use is supported by a wide range of [people and organizations],” OpenAI representatives wrote in Monday’s post, linking out to recently submitted comments from several academics, startups, and content creators to the US Copyright Office. In a letter of support filed by Duolingo, for example, the language learning software company wrote that it believes that “Output generated by an AI trained on copyrighted materials should not automatically be considered infringing—just as a work by a human author would not be considered infringing merely because the human author had learned how to write through reading copyrighted works.” (On Monday, Duolingo confirmed to Bloomberg it has laid off approximately 10 percent of its contractors, citing its increased reliance on AI.) On December 27, The New York Times sued both OpenAI and Microsoft—which currently utilizes the former’s GPT in products like Bing—for copyright infringement. Court documents filed by The Times claim OpenAI trained its generative technology on millions of the publication’s articles without permission or compensation. Products like ChatGPT are now allegedly used in lieu of their source material at a detriment to the media company. More readers opting for AI news summaries presumably means less readers subscribing to source outlets, argues The Times . The New York Times lawsuit is only the latest in a string of similar filings claiming copyright infringement, including one on behalf of notable writers , as well as another for visual artists . Meanwhile, OpenAI is lobbying government regulators over their access to copyrighted material. According to The Telegraph on January 7, a recent letter submitted by OpenAI to the UK’s House of Lords communications and digital argues access to copyrighted materials is vital to the company’s success and product relevancy. “Because copyright today covers virtually every sort of human expression—including blog posts, photographs, forum posts, scraps of software code, and government documents—it would be impossible to train today’s leading AI models without using copyrighted materials,” OpenAI wrote in the letter, while also contending that limiting training data to public domain work, “might yield an interesting experiment, but would not provide AI systems that meet the needs of today’s citizens.” The letter states that it is part of OpenAI’s “mission to ensure that artificial general intelligence benefits all of humanity.” Meanwhile, some critics have swiftly mocked OpenAI’s claim that its program’s existence requires the use of others’ copyrighted work. On the social media platform Bluesky, historian and author Kevin M. Kruse likened OpenAI’s strategy to selling illegally obtained items in a pawn shop. “Rough Translation: We won’t get fabulously right if you don’t let us steal, so please don’t make stealing a crime!” AI expert Gary Marcus also posted to X on Monday.",
      "pubDate": "2024-01-08 22:00:00",
      "image_url": "https://www.popsci.com/uploads/2024/01/08/Depositphotos_639979930_L.jpg?auto=webp&width=1440&height=810",
      "source_id": "popsci",
      "source_priority": 3815,
      "country": [
        "united states of america"
      ],
      "category": [
        "technology"
      ],
      "language": "english",
      "ai_tag": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN",
      "sentiment": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN",
      "sentiment_stats": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN"
    },
    {
      "article_id": "4ec43c1523ec8baf2a73ca4d94f53382",
      "title": "Multiple AI models help robots execute complex plans more transparently",
      "link": "https://techxplore.com/news/2024-01-multiple-ai-robots-complex-transparently.html",
      "keywords": [
        "robotics"
      ],
      "creator": null,
      "video_url": null,
      "description": "Your daily to-do list is likely pretty straightforward: wash the dishes, buy groceries, and other minutiae. It's unlikely you wrote out \"pick up the first dirty dish,\" or \"wash that plate with a sponge,\" because each of these miniature steps within the chore feels intuitive. While we can routinely complete each step without much thought, a robot requires a complex plan that involves more detailed outlines.",
      "content": "Your daily to-do list is likely pretty straightforward: wash the dishes, buy groceries, and other minutiae. It's unlikely you wrote out \"pick up the first dirty dish,\" or \"wash that plate with a sponge,\" because each of these miniature steps within the chore feels intuitive. While we can routinely complete each step without much thought, a robot requires a complex plan that involves more detailed outlines. MIT's Improbable AI Lab, a group within the Computer Science and Artificial Intelligence Laboratory (CSAIL), has offered these machines a helping hand with a new multimodal framework: Compositional Foundation Models for Hierarchical Planning (HiP), which develops detailed, feasible plans with the expertise of three different foundation models. Like OpenAI's GPT-4, the foundation model upon which ChatGPT and Bing Chat were built, these foundation models are trained on massive quantities of data for applications like generating images, translating text, and robotics. The work is published on the arXiv preprint server. Unlike RT2 and other multimodal models that are trained on paired vision, language, and action data, HiP uses three different foundation models each trained on different data modalities. Each foundation model captures a different part of the decision-making process and then works together when it's time to make decisions. HiP removes the need for access to paired vision, language, and action data, which is difficult to obtain. HiP also makes the reasoning process more transparent. What's considered a daily chore for a human can be a robot's \"long-horizon goal\"—an overarching objective that involves completing many smaller steps first—requiring sufficient data to plan, understand, and execute objectives. While computer vision researchers have attempted to build monolithic foundation models for this problem, pairing language, visual, and action data is expensive. Instead, HiP represents a different, multimodal recipe: a trio that cheaply incorporates linguistic, physical, and environmental intelligence into a robot. \"Foundation models do not have to be monolithic,\" says NVIDIA AI researcher Jim Fan, who was not involved in the paper. \"This work decomposes the complex task of embodied agent planning into three constituent models: a language reasoner, a visual world model, and an action planner. It makes a difficult decision-making problem more tractable and transparent.\" The team believes that their system could help these machines accomplish household chores, such as putting away a book or placing a bowl in the dishwasher. Additionally, HiP could assist with multistep construction and manufacturing tasks, like stacking and placing different materials in specific sequences. The CSAIL team tested HiP's acuity on three manipulation tasks, outperforming comparable frameworks. The system reasoned by developing intelligent plans that adapt to new information. First, the researchers requested that it stack different-colored blocks on each other and then place others nearby. The catch: Some of the correct colors weren't present, so the robot had to place white blocks in a color bowl to paint them. HiP often adjusted to these changes accurately, especially compared to state-of-the-art task planning systems like Transformer BC and Action Diffuser, by adjusting its plans to stack and place each square as needed. Another test: arranging objects such as candy and a hammer in a brown box while ignoring other items. Some of the objects it needed to move were dirty, so HiP adjusted its plans to place them in a cleaning box, and then into the brown container. In a third demonstration, the bot was able to ignore unnecessary objects to complete kitchen sub-goals such as opening a microwave, clearing a kettle out of the way, and turning on a light. Some of the prompted steps had already been completed, so the robot adapted by skipping those directions. HiP's three-pronged planning process operates as a hierarchy, with the ability to pre-train each of its components on different sets of data, including information outside of robotics. At the bottom of that order is a large language model (LLM), which starts to ideate by capturing all the symbolic information needed and developing an abstract task plan. Applying the common sense knowledge it finds on the internet, the model breaks its objective into sub-goals. For example, \"making a cup of tea\" turns into \"filling a pot with water,\" \"boiling the pot,\" and the subsequent actions required. \"All we want to do is take existing pre-trained models and have them successfully interface with each other,\" says Anurag Ajay, a Ph.D. student in the MIT Department of Electrical Engineering and Computer Science (EECS) and a CSAIL affiliate. \"Instead of pushing for one model to do everything, we combine multiple ones that leverage different modalities of internet data. When used in tandem, they help with robotic decision-making and can potentially aid with tasks in homes, factories, and construction sites.\" These models also need some form of \"eyes\" to understand the environment in which they're operating and correctly execute each sub-goal. The team used a large video diffusion model to augment the initial planning completed by the LLM, which collects geometric and physical information about the world from footage on the internet. In turn, the video model generates an observation trajectory plan, refining the LLM's outline to incorporate new physical knowledge. This process, known as iterative refinement, allows HiP to reason about its ideas, taking in feedback at each stage to generate a more practical outline. The flow of feedback is similar to writing an article, where an author may send their draft to an editor, and with revisions incorporated, the publisher reviews for any last changes and finalizes. In this case, the top of the hierarchy is an egocentric action model, or a sequence of first-person images that infer which actions should take place based on its surroundings. During this stage, the observation plan from the video model is mapped over the space visible to the robot, helping the machine decide how to execute each task within the long-horizon goal. If a robot uses HiP to make tea, this means it will have mapped out exactly where the pot, sink, and other key visual elements are, and begin completing each sub-goal. Still, the multimodal work is limited by the lack of high-quality video foundation models. Once available, they could interface with HiP's small-scale video models to further enhance visual sequence prediction and robot action generation. A higher-quality version would also reduce the current data requirements of the video models. That being said, the CSAIL team's approach only used a tiny bit of data overall. Moreover, HiP was cheap to train and demonstrated the potential of using readily available foundation models to complete long-horizon tasks. \"What Anurag has demonstrated is proof-of-concept of how we can take models trained on separate tasks and data modalities and combine them into models for robotic planning. In the future, HiP could be augmented with pre-trained models that can process touch and sound to make better plans,\" says senior author Pulkit Agrawal, MIT assistant professor in EECS and director of the Improbable AI Lab. The group is also considering applying HiP to solving real-world long-horizon tasks in robotics. Ajay and Agrawal are lead authors on a paper describing the work. They are joined by MIT professors and CSAIL principal investigators Tommi Jaakkola, Joshua Tenenbaum, and Leslie Pack Kaelbling; CSAIL research affiliate and MIT-IBM AI Lab research manager Akash Srivastava; graduate students Seungwook Han and Yilun Du; former postdoc Abhishek Gupta, who is now assistant professor at University of Washington; and former graduate student Shuang Li, Ph.D. More information: Anurag Ajay et al, Compositional Foundation Models for Hierarchical Planning, arXiv (2023). DOI: 10.48550/arxiv.2309.08587 This story is republished courtesy of MIT News ( web.mit.edu/newsoffice/ ), a popular site that covers news about MIT research, innovation and teaching.",
      "pubDate": "2024-01-08 21:36:06",
      "image_url": "https://scx1.b-cdn.net/csz/news/tmb/2024/multiple-ai-models-hel.jpg",
      "source_id": "phys",
      "source_priority": 6461,
      "country": [
        "india",
        "singapore",
        "united kingdom",
        "united states of america",
        "australia"
      ],
      "category": [
        "technology"
      ],
      "language": "english",
      "ai_tag": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN",
      "sentiment": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN",
      "sentiment_stats": "ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLAN"
    }
  ],
  "nextPage": "1704749766732628806"
}
